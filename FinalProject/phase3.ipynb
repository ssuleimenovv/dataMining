{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 3: E-commerce Fraud Detection System\n",
    "## Advanced ML for Marketplace Fraud Detection\n",
    "\n",
    "**Goal:** Build production-ready fraud detection system with 5 fraud indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, auc,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('all_products.csv')\n",
    "print(f\"Dataset: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART A: SUPERVISED CLASSIFICATION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Analysis & Fraud Label Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data distributions\n",
    "print(\"DATA ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "key_cols = ['price_rub', 'seller_rating', 'seller_total_sold', 'seller_age_months', 'feedbacks']\n",
    "\n",
    "for col in key_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Count: {df[col].notna().sum():,}\")\n",
    "        print(f\"  Missing: {df[col].isna().sum():,} ({df[col].isna().sum()/len(df)*100:.1f}%)\")\n",
    "        if df[col].notna().sum() > 0:\n",
    "            print(f\"  Min: {df[col].min():.2f}\")\n",
    "            print(f\"  Max: {df[col].max():.2f}\")\n",
    "            print(f\"  Mean: {df[col].mean():.2f}\")\n",
    "            print(f\"  Median: {df[col].median():.2f}\")\n",
    "            print(f\"  Zeros: {(df[col] == 0).sum():,} ({(df[col] == 0).sum()/df[col].notna().sum()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fraud labels with STRICT business logic\n",
    "df_fraud = df.copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING FRAUD LABELS - STRICT CRITERIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate statistics for price outliers\n",
    "category_stats = df_fraud.groupby('category')['price_rub'].agg(['mean', 'std']).reset_index()\n",
    "category_stats.columns = ['category', 'cat_mean', 'cat_std']\n",
    "df_fraud = df_fraud.merge(category_stats, on='category', how='left')\n",
    "df_fraud['price_zscore'] = np.abs((df_fraud['price_rub'] - df_fraud['cat_mean']) / (df_fraud['cat_std'] + 1))\n",
    "\n",
    "# ============================================================\n",
    "# 1. is_fake_reviews: Suspicious review patterns\n",
    "# ============================================================\n",
    "# Only flag if feedbacks actually exists and is suspicious\n",
    "df_fraud['is_fake_reviews'] = 0\n",
    "\n",
    "# Check if feedbacks column has meaningful data\n",
    "if df_fraud['feedbacks'].notna().sum() > 0 and df_fraud['feedbacks'].max() > 0:\n",
    "    feedback_high = df_fraud['feedbacks'].quantile(0.9)  # Top 10%\n",
    "    age_young = 6  # Less than 6 months\n",
    "    \n",
    "    df_fraud['is_fake_reviews'] = (\n",
    "        # Many reviews but very new seller (suspicious growth)\n",
    "        ((df_fraud['feedbacks'] > feedback_high) & \n",
    "         (df_fraud['seller_age_months'] < age_young)) |\n",
    "        # Many reviews but terrible rating (fake positive reviews)\n",
    "        ((df_fraud['feedbacks'] > df_fraud['feedbacks'].median()) & \n",
    "         (df_fraud['seller_rating'] < 3.5))\n",
    "    ).astype(int)\n",
    "\n",
    "print(f\"\\n1. is_fake_reviews:\")\n",
    "print(f\"   Logic: High feedbacks (>{feedback_high:.0f}) + new seller (<6 months)\")\n",
    "print(f\"          OR High feedbacks + low rating (<3.5)\")\n",
    "print(f\"   Result: {df_fraud['is_fake_reviews'].sum():,} / {len(df_fraud):,} ({df_fraud['is_fake_reviews'].mean()*100:.2f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. is_fraud_seller: MAIN TARGET - Low rating sellers\n",
    "# ============================================================\n",
    "RATING_THRESHOLD = 3.8  # Your requirement\n",
    "AGE_THRESHOLD = 12      # Less than 1 year = risky\n",
    "\n",
    "df_fraud['is_fraud_seller'] = 0\n",
    "\n",
    "# Condition 1: Low rating (main indicator)\n",
    "df_fraud['is_fraud_seller'] = (df_fraud['seller_rating'] < RATING_THRESHOLD).astype(int)\n",
    "\n",
    "# Condition 2: Low rating + young account (double risk)\n",
    "df_fraud.loc[\n",
    "    (df_fraud['seller_rating'] < RATING_THRESHOLD) & \n",
    "    (df_fraud['seller_age_months'] < AGE_THRESHOLD),\n",
    "    'is_fraud_seller'\n",
    "] = 1\n",
    "\n",
    "# Condition 3: Extremely low rating (always fraud)\n",
    "df_fraud.loc[df_fraud['seller_rating'] < 3.0, 'is_fraud_seller'] = 1\n",
    "\n",
    "print(f\"\\n2. is_fraud_seller (MAIN TARGET):\")\n",
    "print(f\"   Logic: seller_rating < {RATING_THRESHOLD}\")\n",
    "print(f\"          OR (rating < {RATING_THRESHOLD} AND age < {AGE_THRESHOLD} months)\")\n",
    "print(f\"          OR rating < 3.0\")\n",
    "print(f\"   Result: {df_fraud['is_fraud_seller'].sum():,} / {len(df_fraud):,} ({df_fraud['is_fraud_seller'].mean()*100:.2f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. is_low_quality: Proven bad quality (many complaints)\n",
    "# ============================================================\n",
    "df_fraud['is_low_quality'] = 0\n",
    "\n",
    "if df_fraud['feedbacks'].notna().sum() > 0 and df_fraud['feedbacks'].max() > 0:\n",
    "    feedback_median = df_fraud['feedbacks'].median()\n",
    "    \n",
    "    df_fraud['is_low_quality'] = (\n",
    "        # Low rating with many feedbacks = proven bad quality\n",
    "        (df_fraud['seller_rating'] < 4.0) & \n",
    "        (df_fraud['feedbacks'] > feedback_median)\n",
    "    ).astype(int)\n",
    "\n",
    "print(f\"\\n3. is_low_quality:\")\n",
    "print(f\"   Logic: rating < 4.0 AND feedbacks > median\")\n",
    "print(f\"   Result: {df_fraud['is_low_quality'].sum():,} / {len(df_fraud):,} ({df_fraud['is_low_quality'].mean()*100:.2f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. is_price_manipulation: Extreme price outliers only\n",
    "# ============================================================\n",
    "ZSCORE_THRESHOLD = 3  # 3 standard deviations = extreme outlier\n",
    "\n",
    "df_fraud['is_price_manipulation'] = (\n",
    "    # Only extreme outliers (3+ std deviations)\n",
    "    df_fraud['price_zscore'] > ZSCORE_THRESHOLD\n",
    ").astype(int)\n",
    "\n",
    "print(f\"\\n4. is_price_manipulation:\")\n",
    "print(f\"   Logic: price z-score > {ZSCORE_THRESHOLD} (extreme outlier)\")\n",
    "print(f\"   Result: {df_fraud['is_price_manipulation'].sum():,} / {len(df_fraud):,} ({df_fraud['is_price_manipulation'].mean()*100:.2f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. fraud_score: Composite score (0-100)\n",
    "# ============================================================\n",
    "df_fraud['fraud_score'] = (\n",
    "    df_fraud['is_fake_reviews'] * 15 +\n",
    "    df_fraud['is_fraud_seller'] * 50 +      # Most important (50%)\n",
    "    df_fraud['is_low_quality'] * 15 +\n",
    "    df_fraud['is_price_manipulation'] * 10 +\n",
    "    # Continuous penalty based on rating\n",
    "    ((5 - df_fraud['seller_rating'].clip(1, 5)) / 4 * 10)\n",
    ").clip(0, 100)\n",
    "\n",
    "print(f\"\\n5. fraud_score (0-100):\")\n",
    "print(f\"   Weights: fake_reviews(15%) + fraud_seller(50%) + low_quality(15%) + price(10%) + rating_penalty(10%)\")\n",
    "print(f\"   Mean: {df_fraud['fraud_score'].mean():.2f}\")\n",
    "print(f\"   Median: {df_fraud['fraud_score'].median():.2f}\")\n",
    "print(f\"   High risk (>50): {(df_fraud['fraud_score'] > 50).sum():,} ({(df_fraud['fraud_score'] > 50).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify fraud labels\n",
    "fraud_cols = ['is_fake_reviews', 'is_fraud_seller', 'is_low_quality', 'is_price_manipulation']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FRAUD LABEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in fraud_cols:\n",
    "    count = df_fraud[col].sum()\n",
    "    pct = df_fraud[col].mean() * 100\n",
    "    print(f\"{col:25s}: {count:5,} ({pct:5.2f}%)\")\n",
    "\n",
    "df_fraud['any_fraud'] = (df_fraud[fraud_cols].sum(axis=1) > 0).astype(int)\n",
    "print(f\"\\n{'ANY fraud flag':25s}: {df_fraud['any_fraud'].sum():5,} ({df_fraud['any_fraud'].mean()*100:5.2f}%)\")\n",
    "\n",
    "# Check if we have enough fraud cases for ML\n",
    "fraud_count = df_fraud['is_fraud_seller'].sum()\n",
    "if fraud_count < 50:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Only {fraud_count} fraud cases! May need to adjust thresholds.\")\n",
    "elif fraud_count > len(df_fraud) * 0.4:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Too many fraud cases ({fraud_count}/{len(df_fraud)} = {fraud_count/len(df_fraud)*100:.1f}%)!\")\n",
    "    print(\"   Thresholds may be too lenient.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Good fraud rate: {fraud_count} cases ({fraud_count/len(df_fraud)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud labels\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "for i, col in enumerate(fraud_cols):\n",
    "    ax = axes[i//3, i%3]\n",
    "    counts = df_fraud[col].value_counts()\n",
    "    bars = ax.bar(['Normal', 'Fraud'], [counts.get(0, 0), counts.get(1, 0)], \n",
    "                   color=['green', 'red'], alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(col.replace('_', ' ').title(), fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for j, v in enumerate([counts.get(0, 0), counts.get(1, 0)]):\n",
    "        if v > 0:\n",
    "            ax.text(j, v + 50, f'{v:,}\\n({v/len(df_fraud)*100:.1f}%)', \n",
    "                   ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Fraud score\n",
    "ax = axes[1, 1]\n",
    "ax.hist(df_fraud['fraud_score'], bins=50, color='orange', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(50, color='red', linestyle='--', linewidth=2, label='High Risk (>50)')\n",
    "ax.set_title('Fraud Score Distribution', fontweight='bold', fontsize=12)\n",
    "ax.set_xlabel('Score (0-100)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Any fraud\n",
    "ax = axes[1, 2]\n",
    "counts = df_fraud['any_fraud'].value_counts()\n",
    "ax.bar(['Clean', 'Fraud'], [counts.get(0, 0), counts.get(1, 0)], \n",
    "       color=['green', 'red'], alpha=0.7, edgecolor='black')\n",
    "ax.set_title('Overall Fraud Status', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Count')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "for j, v in enumerate([counts.get(0, 0), counts.get(1, 0)]):\n",
    "    if v > 0:\n",
    "        ax.text(j, v + 50, f'{v:,}\\n({v/len(df_fraud)*100:.1f}%)', \n",
    "               ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions by fraud status\n",
    "TARGET = 'is_fraud_seller'\n",
    "\n",
    "features = ['price_rub', 'seller_rating', 'seller_age_months']\n",
    "# Only use features that have data\n",
    "features = [f for f in features if df_fraud[f].notna().sum() > 100]\n",
    "\n",
    "if len(features) > 0:\n",
    "    fig, axes = plt.subplots(1, len(features), figsize=(6*len(features), 5))\n",
    "    if len(features) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, col in enumerate(features):\n",
    "        fraud = df_fraud[df_fraud[TARGET] == 1][col].dropna()\n",
    "        normal = df_fraud[df_fraud[TARGET] == 0][col].dropna()\n",
    "        \n",
    "        if len(fraud) > 0 and len(normal) > 0:\n",
    "            axes[i].hist(normal, bins=50, alpha=0.6, label='Normal', color='green', density=True)\n",
    "            axes[i].hist(fraud, bins=50, alpha=0.6, label='Fraud', color='red', density=True)\n",
    "            axes[i].set_title(col, fontweight='bold')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Density')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough feature data for distribution plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "corr_cols = features + fraud_cols + ['fraud_score']\n",
    "df_corr = df_fraud[corr_cols].dropna()\n",
    "\n",
    "if len(df_corr) > 0:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr_matrix = df_corr.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdYlGn_r', center=0, \n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop correlations with fraud:\")\n",
    "    fraud_corr = corr_matrix[TARGET].abs().sort_values(ascending=False)\n",
    "    print(fraud_corr.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "model_features = [f for f in features if f in df_fraud.columns]\n",
    "df_model = df_fraud[model_features + [TARGET]].dropna()\n",
    "\n",
    "X = df_model[model_features]\n",
    "y = df_model[TARGET]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL TRAINING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nDataset: {X.shape}\")\n",
    "print(f\"Features: {model_features}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Check if we can proceed\n",
    "if len(y.value_counts()) < 2:\n",
    "    print(\"\\n‚ùå ERROR: Only one class! Cannot train models.\")\n",
    "    raise ValueError(\"Insufficient fraud cases for training\")\n",
    "\n",
    "if y.sum() < 20:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Very few fraud cases ({y.sum()}). Results may be unreliable.\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {X_train.shape} ({y_train.sum()} fraud, {(y_train==0).sum()} normal)\")\n",
    "print(f\"Test:  {X_test.shape} ({y_test.sum()} fraud, {(y_test==0).sum()} normal)\")\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imbalance\n",
    "print(f\"\\nClass balance strategy:\")\n",
    "\n",
    "if y_train.sum() >= 6:  # Need at least 6 minority samples for SMOTE\n",
    "    try:\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "        print(f\"‚úÖ SMOTE applied\")\n",
    "        print(f\"   Before: Normal={( y_train==0).sum()}, Fraud={y_train.sum()}\")\n",
    "        print(f\"   After:  Normal={(y_train_balanced==0).sum()}, Fraud={y_train_balanced.sum()}\")\n",
    "        use_smote = True\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è SMOTE failed, using class weights\")\n",
    "        X_train_balanced = X_train_scaled\n",
    "        y_train_balanced = y_train\n",
    "        use_smote = False\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Too few minority samples, using class weights\")\n",
    "    X_train_balanced = X_train_scaled\n",
    "    y_train_balanced = y_train\n",
    "    use_smote = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"\\nTraining Logistic Regression...\")\n",
    "if use_smote:\n",
    "    lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr.fit(X_train_balanced, y_train_balanced)\n",
    "else:\n",
    "    lr = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "models['Logistic Regression'] = lr\n",
    "\n",
    "# Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "if use_smote:\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train_balanced, y_train_balanced)\n",
    "else:\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', \n",
    "                                random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "models['Random Forest'] = rf\n",
    "\n",
    "# Gradient Boosting\n",
    "print(\"Training Gradient Boosting...\")\n",
    "if use_smote:\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "    gb.fit(X_train_balanced, y_train_balanced)\n",
    "else:\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "    gb.fit(X_train_scaled, y_train)\n",
    "models['Gradient Boosting'] = gb\n",
    "\n",
    "print(\"\\n‚úÖ All models trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_proba)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1': f1,\n",
    "        'ROC-AUC': roc,\n",
    "        'PR-AUC': pr_auc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_idx = results_df['F1'].idxmax()\n",
    "best = results_df.loc[best_idx]\n",
    "print(f\"\\nüèÜ Best Model: {best['Model']} (F1={best['F1']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Normal', 'Fraud'],\n",
    "                yticklabels=['Normal', 'Fraud'])\n",
    "    axes[i].set_title(name, fontweight='bold')\n",
    "    axes[i].set_ylabel('True')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC & PR Curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = {'Logistic Regression': 'blue', 'Random Forest': 'green', 'Gradient Boosting': 'red'}\n",
    "\n",
    "# ROC\n",
    "for name, model in models.items():\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    axes[0].plot(fpr, tpr, label=f'{name} (AUC={roc_auc:.3f})', \n",
    "                color=colors[name], linewidth=2)\n",
    "\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curves', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PR\n",
    "for name, model in models.items():\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    axes[1].plot(recall, precision, label=f'{name} (AUC={pr_auc:.3f})', \n",
    "                color=colors[name], linewidth=2)\n",
    "\n",
    "baseline = y_test.mean()\n",
    "axes[1].axhline(y=baseline, color='k', linestyle='--', label=f'Baseline ({baseline:.3f})', linewidth=1)\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curves', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (Random Forest)\n",
    "if hasattr(rf, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': model_features,\n",
    "        'Importance': rf.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance (Random Forest):\")\n",
    "    print(importance_df.to_string(index=False))\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'], color='steelblue', alpha=0.7)\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Feature Importance', fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Business Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FRAUD DETECTION SYSTEM - RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüéØ FRAUD DETECTION CRITERIA:\")\n",
    "print(f\"   ‚Ä¢ Low rating: seller_rating < {RATING_THRESHOLD}\")\n",
    "print(f\"   ‚Ä¢ Young account: seller_age_months < {AGE_THRESHOLD}\")\n",
    "print(f\"   ‚Ä¢ Price outlier: z-score > {ZSCORE_THRESHOLD}\")\n",
    "\n",
    "print(f\"\\nüìä FRAUD STATISTICS:\")\n",
    "print(f\"   Total products: {len(df_fraud):,}\")\n",
    "print(f\"   Fraud sellers: {df_fraud['is_fraud_seller'].sum():,} ({df_fraud['is_fraud_seller'].mean()*100:.2f}%)\")\n",
    "print(f\"   Fake reviews: {df_fraud['is_fake_reviews'].sum():,} ({df_fraud['is_fake_reviews'].mean()*100:.2f}%)\")\n",
    "print(f\"   Low quality: {df_fraud['is_low_quality'].sum():,} ({df_fraud['is_low_quality'].mean()*100:.2f}%)\")\n",
    "print(f\"   Price manipulation: {df_fraud['is_price_manipulation'].sum():,} ({df_fraud['is_price_manipulation'].mean()*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best['Model']}\")\n",
    "print(f\"   F1-Score:  {best['F1']:.4f}\")\n",
    "print(f\"   Precision: {best['Precision']:.4f} ({best['Precision']*100:.1f}% of flagged are real fraud)\")\n",
    "print(f\"   Recall:    {best['Recall']:.4f} (catches {best['Recall']*100:.1f}% of frauds)\")\n",
    "print(f\"   ROC-AUC:   {best['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "if hasattr(rf, 'feature_importances_'):\n",
    "    print(f\"   Most important: {importance_df.iloc[0]['Feature']} ({importance_df.iloc[0]['Importance']:.3f})\")\n",
    "print(f\"   Main fraud indicator: seller_rating < {RATING_THRESHOLD}\")\n",
    "print(f\"   System ready for production\")\n",
    "\n",
    "print(\"\\n‚úÖ CLASSIFICATION COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART B: CLUSTERING - SELLER SEGMENTATION\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare clustering data\n",
    "cluster_features = [f for f in ['seller_rating', 'seller_age_months', 'price_rub'] \n",
    "                    if f in df_fraud.columns and df_fraud[f].notna().sum() > 100]\n",
    "\n",
    "df_cluster = df_fraud[cluster_features].dropna()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PART B: SELLER CLUSTERING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nDataset: {df_cluster.shape}\")\n",
    "print(f\"Features: {cluster_features}\")\n",
    "\n",
    "# Scale\n",
    "scaler_c = StandardScaler()\n",
    "X_cluster = scaler_c.fit_transform(df_cluster)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_cluster)\n",
    "\n",
    "print(f\"\\nPCA variance explained: {pca.explained_variance_ratio_.sum()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal k\n",
    "K_range = range(2, 9)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_cluster)\n",
    "    inertias.append(km.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_cluster, labels))\n",
    "\n",
    "optimal_k = K_range[np.argmax(silhouettes)]\n",
    "print(f\"\\nOptimal k: {optimal_k} (silhouette={max(silhouettes):.3f})\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(K_range, inertias, 'bo-', linewidth=2)\n",
    "axes[0].set_xlabel('k')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "axes[0].set_title('Elbow Method')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(K_range, silhouettes, 'ro-', linewidth=2)\n",
    "axes[1].axvline(optimal_k, color='g', linestyle='--', label=f'Optimal k={optimal_k}')\n",
    "axes[1].set_xlabel('k')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_title('Silhouette Analysis')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final clustering\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_cluster)\n",
    "df_cluster['cluster'] = clusters\n",
    "\n",
    "print(f\"\\nClusters:\")\n",
    "print(df_cluster['cluster'].value_counts().sort_index())\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', alpha=0.6, s=10)\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "plt.title(f'K-Means Clustering (k={optimal_k})', fontweight='bold')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster profiles\n",
    "profiles = df_cluster.groupby('cluster')[cluster_features].mean()\n",
    "print(\"\\nCluster Profiles:\")\n",
    "print(profiles.round(2))\n",
    "\n",
    "# Add fraud rates\n",
    "df_cluster['is_fraud'] = df_fraud.loc[df_cluster.index, 'is_fraud_seller']\n",
    "fraud_rates = df_cluster.groupby('cluster')['is_fraud'].agg(['mean', 'sum', 'count'])\n",
    "fraud_rates.columns = ['Fraud_Rate', 'Fraud_Count', 'Total']\n",
    "fraud_rates['Fraud_Rate'] *= 100\n",
    "print(\"\\nFraud Rates:\")\n",
    "print(fraud_rates.round(2))\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 5))\n",
    "profiles_norm = (profiles - profiles.mean()) / profiles.std()\n",
    "sns.heatmap(profiles_norm.T, annot=True, fmt='.2f', cmap='RdYlGn', center=0, linewidths=1)\n",
    "plt.title('Cluster Profiles (Normalized)', fontweight='bold')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business interpretation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLUSTER INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for c in range(optimal_k):\n",
    "    data = df_cluster[df_cluster['cluster'] == c]\n",
    "    rating = data['seller_rating'].mean() if 'seller_rating' in cluster_features else 0\n",
    "    age = data['seller_age_months'].mean() if 'seller_age_months' in cluster_features else 0\n",
    "    price = data['price_rub'].mean() if 'price_rub' in cluster_features else 0\n",
    "    fraud_rate = data['is_fraud'].mean()\n",
    "    \n",
    "    print(f\"\\nCluster {c} ({len(data):,} sellers):\")\n",
    "    if 'seller_rating' in cluster_features:\n",
    "        print(f\"  Rating: {rating:.2f}\")\n",
    "    if 'seller_age_months' in cluster_features:\n",
    "        print(f\"  Age: {age:.1f} months\")\n",
    "    if 'price_rub' in cluster_features:\n",
    "        print(f\"  Avg Price: {price:.0f} RUB\")\n",
    "    print(f\"  Fraud rate: {fraud_rate*100:.1f}%\")\n",
    "    \n",
    "    if fraud_rate > 0.3:\n",
    "        label = \"üö® HIGH RISK\"\n",
    "    elif fraud_rate > 0.15:\n",
    "        label = \"‚ö†Ô∏è MEDIUM RISK\"\n",
    "    elif rating >= 4.5:\n",
    "        label = \"üåü TRUSTED\"\n",
    "    else:\n",
    "        label = \"‚úÖ RELIABLE\"\n",
    "    \n",
    "    print(f\"  Label: {label}\")\n",
    "\n",
    "print(\"\\n‚úÖ CLUSTERING COMPLETE\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ PHASE 3 COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
